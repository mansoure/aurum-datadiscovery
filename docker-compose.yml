# For a simple Aurum setup, install Docker Compose
# <https://docs.docker.com/compose/install/> and run these commands:
#
# 1. docker-compose up -d elasticsearch
#     Brings up an elasticsearch instance using the data located at data/elasticsearch. This data persists even if you destroy and recreate the elasticsearch Docker container.
# 2. docker-compose run --rm -T profiler
#     Runs the ddprofiler with the CSVs located in data/csvs. Writes to the above elasticsearch container.
# 3. docker-compose run --rm -T nbc
#     Runs networkbuildercoordinator.py with the above elasticsearch and saves its files to data/pickles.
# 4. docker-compose up notebook
#     Runs a Jupyter notebook with Aurum libraries and the above pickles from data/pickles.
# 5. docker-compose up frontend
#     Runs the web frontend and API on http://localhost:3000 and http://localhost:5000 respectively. Uses pickles from data/pickles.

version: '3'
services:
  elasticsearch:
    image: elasticsearch:2.3.3
    # volumes:
    #   - $PWD/data/elasticsearch:/usr/share/elasticsearch/data
    # environment:
    #         - cluster.name=Docker-elasticsearch
    #         - node.name="ES-node"
    #         - http.host=0.0.0.0
    #         - transport.host=0.0.0.0        
    #         - network.publish_host=127.0.0.1
    #         - transport.tcp.port=9300
    #         - transport.publish_port=9200
    #         # - discovery.type=single-node
    #         # - xpack.security.enabled=false
    #         - client.transport.sniff=true
    ports:
      - "9200:9200"
      - "9300:9300"
  frontend:
    depends_on:
      - elasticsearch
    image: aurum/frontend
    build:
      context: $PWD
      dockerfile: docker/Dockerfile-ui
    # volumes:
    #   - $PWD/data/models:/aurum/data/models
    #   - $PWD/data/pickles:/aurum/data/pickles
    ports:
      - "3000:3000"
      - "5000:5000"
  profiler:
    depends_on:
      - elasticsearch
    image: aurum/ddprofiler
    build:
      context: $PWD
      dockerfile: docker/Dockerfile-ddprofiler
    # volumes:
    #   - $PWD/data
  nbc:
    depends_on:
      - elasticsearch
    image: aurum/networkbuildercoordinator
    build:
      context: .
      dockerfile: docker/Dockerfile-networkbuildercoordinator
    # volumes:
    #   - $PWD/data/models:/output
  notebook:
    depends_on:
      - elasticsearch
    image: aurum/notebook
    build:
      context: .
      dockerfile: docker/Dockerfile-jupyter-notebook
    # volumes:
    #   - $PWD/data/models
    ports:
      - "8888:8888"
